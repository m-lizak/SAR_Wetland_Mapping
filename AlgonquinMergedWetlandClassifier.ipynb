{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6177ed1-036f-43db-9408-6ca4d6e1cba7",
   "metadata": {},
   "source": [
    "**Reclassifying training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c9042-674a-4254-a0a7-6cdf00ca2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"trainingAlgonquin.tif\"\n",
    "output_file = \"trainingAlgonquinMerged.tif\"\n",
    "\n",
    "# Define the reclassification dictionary\n",
    "reclass_dict = {\n",
    "    0: 0,  # Set NoData values to a specific integer value\n",
    "    1: 1,      # Fen to Peatland\n",
    "    2: 2,      # Reclassify Swamp to Organic Wetlands\n",
    "    3: 2,      # Reclassify Marsh to Organic Wetlands\n",
    "    4: 1,      # Reclassify Bog to Peatlands\n",
    "    5: 3,      # Keep Open Water\n",
    "    6: 4,      # Keep Forest\n",
    "    7: 5,      # Keep Vegetated Land\n",
    "    8: 6       # Keep Barren Land\n",
    "}\n",
    "\n",
    "# Open the input raster dataset in read mode\n",
    "with rasterio.open(input_file) as src:\n",
    "    # Read the raster data as a numpy array\n",
    "    raster_data = src.read(1)\n",
    "\n",
    "    # Apply NoData mask to the raster data\n",
    "    raster_data = np.ma.masked_equal(raster_data, src.nodata)\n",
    "\n",
    "    # Reclassify the raster data according to the reclassification dictionary\n",
    "    reclassified_data = np.vectorize(reclass_dict.get)(raster_data)\n",
    "\n",
    "    # Update metadata for the output raster\n",
    "    profile = src.profile\n",
    "    profile.update(dtype=rasterio.uint8)  # Update data type if needed\n",
    "\n",
    "    # Write the reclassified raster data to the output file\n",
    "    with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "        dst.write(reclassified_data.filled(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1f316-4601-4b6e-b2a9-1347b40c1748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71969607-fbf2-470b-ac34-c4ce8093ef85",
   "metadata": {},
   "source": [
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6dfca-e3a4-4b80-b144-b42b5c3ec223",
   "metadata": {},
   "source": [
    "**This script uses the rasterio and subprocess modules to warp a raster image specified by 'image_ds_path' to a new extent, coordinate reference system (CRS), and resolution. It then saves the warped image as 'trainingAlgonquinWarp.tif' using GDAL's gdalwarp command-line utility.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffeab39c-b320-4a5e-a458-8db30bccb9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 4330P x 3687L.\n",
      "Processing trainingAlgonquinMerged.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "4330 3687\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import subprocess\n",
    "import joblib\n",
    "\n",
    "# Read in our image and training / testing samples\n",
    "training_ds_original = \"trainingAlgonquinMerged.tif\" # Original training dataset path\n",
    "training_ds_path = \"trainingAlgonquinMergedWarp.tif\" # Desired warped training ds path\n",
    "\n",
    "image_ds_path = \"/Users/maciej/Library/CloudStorage/OneDrive-UniversityofGuelph/Grad School/Winter 2024/GEOG 6550/Project Folder/Updated RCM Imagery and Decompositions/Image Stacks/All Variables/RCM_PALSAR_S1_Terrain.tif\"\n",
    "model_desc = \"RCM_PALSAR_S1_Terrain_Class_Merge\" #Update with naming convention for model outputs\n",
    "\n",
    "# Load the trained Random Forest model\n",
    "rf = joblib.load(f\"{model_desc}_model.pkl\")\n",
    "\n",
    "target_file = image_ds_path\n",
    "with rasterio.open(target_file) as src:\n",
    "    profile = src.profile\n",
    "\n",
    "aff = profile['transform']\n",
    "width = profile['width']\n",
    "height = profile['height']\n",
    "crs = profile['crs']['init']\n",
    "\n",
    "xmin = aff[2]\n",
    "xmax = aff[2] + width*aff[0]\n",
    "ymax = aff[5]\n",
    "ymin = aff[5] + height*aff[4]\n",
    "\n",
    "\n",
    "command = [\n",
    "    'gdalwarp',\n",
    "    '-te', str(xmin), str(ymin), str(xmax), str(ymax),\n",
    "    '-te_srs', crs,\n",
    "    '-t_srs', crs,\n",
    "    '-tr', '30', '30',\n",
    "    '-tap',\n",
    "    '-co', 'COMPRESS=LZW',\n",
    "    '-overwrite',\n",
    "    training_ds_original,\n",
    "    training_ds_path\n",
    "]\n",
    "\n",
    "\n",
    "subprocess.call(command)\n",
    "\n",
    "print(width, height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16c47b-5804-4b19-874c-76ddb45eec87",
   "metadata": {},
   "source": [
    "**This script prepares raster data for further analysis by reading both the image and training data into NumPy arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3ab695-c1b9-45b9-83d2-c45d022e9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3687, 4330)\n",
      "(3687, 4330, 63)\n",
      "Height: 3687 Width 4330 Depth: 63\n"
     ]
    }
   ],
   "source": [
    "# Import Python 3's print function and division\n",
    "from __future__ import print_function, division\n",
    " \n",
    "# Import GDAL, NumPy, and matplotlib\n",
    "from osgeo import gdal, gdal_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()\n",
    "\n",
    "img_ds = gdal.Open(image_ds_path, gdal.GA_ReadOnly)     #Image Dataset\n",
    "dataset = gdal.Open(training_ds_path, gdal.GA_ReadOnly) #Training Dataset\n",
    "\n",
    "\n",
    "img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "for b in range(img.shape[2]):\n",
    "    img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    " \n",
    "ds = dataset.GetRasterBand(1).ReadAsArray().astype(np.uint8)\n",
    "\n",
    "\n",
    "print(ds.shape)\n",
    "print(img.shape)\n",
    "\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "depth = img.shape[2]\n",
    "print(\"Height:\", height, \"Width\", width, \"Depth:\", depth)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7989b3e-4561-49a3-803f-51a7b36d2394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8099c438-e0c3-4386-866d-a52364508655",
   "metadata": {},
   "source": [
    "**This script performs stratified random sampling to split a dataset into training and test subsets while maintaining class distribution. It then uses the `train_test_split` function from scikit-learn to split the sampled data into training and testing subsets, ensuring reproducibility by setting the random seed `SEED`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0648417f-2f64-41dd-bc0a-9f606f82afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (15964710, 63)\n",
      "Shape of y: (15964710,)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Import the classification report and accuracies\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = np.random.seed(1234)  # Set the seed using numpy\n",
    "\n",
    "X = img.reshape((width*height, depth))\n",
    "y = ds.flatten()\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Stratified random sampling\n",
    "fraction = 0.2          #Define what fraction of all samples should be used for training/validation\n",
    "min_samples = 2000      #Define the minimum # of sample to be used by any given class\n",
    "Xsample = []\n",
    "ysample = []\n",
    "for i in range(1, 7):  #We ignore class 0 here which is noData\n",
    "    Ntotal = (y == i).sum()\n",
    "    Nsample = max(int(fraction*Ntotal), min_samples)\n",
    "    idx = np.where(y == i)[0]\n",
    "    s_idx = np.random.choice(idx, Nsample)\n",
    "    Xsample.append(X[s_idx,:])\n",
    "    ysample.append(np.repeat(i, Nsample))\n",
    "\n",
    "Xsample = np.vstack(Xsample)\n",
    "ysample = np.hstack(ysample)\n",
    "\n",
    "# Split the data with the seeded random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xsample, ysample, test_size=0.3, random_state=SEED) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b63cc8-b358-47ef-929b-2c672d2e164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)      #Prints the number of unique classes found within the sample subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f19968-add5-4424-ab3e-b094c16416ce",
   "metadata": {},
   "source": [
    "**The randomForest model is fit to the training data and saved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4f46e-e6bc-4ae1-bf14-195f9595bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# User-defined number of decision trees\n",
    "trees = 500  # Default = 100, can be changed\n",
    "\n",
    "# Initialize our model with the specified hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=trees, n_jobs=-2, verbose=3) # specify trees, use all but one core, display progress\n",
    "\n",
    "# Fit our model to training data\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(rf, f\"{model_desc}_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e5aa6-4b54-4dc1-9ece-2cfa2962a376",
   "metadata": {},
   "source": [
    "**Model Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2aa6bfe-a947-4b3d-b640-6969509c720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=7)]: Done 114 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=7)]: Done 274 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=7)]: Done 500 out of 500 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  [0.63467947 0.91981511 0.97334145 0.92355181 0.984      1.        ]\n",
      "\n",
      "Recall:  [0.59729974 0.15045528 0.97892256 0.9927419  0.157289   0.1411215 ]\n",
      "\n",
      "F1:  [0.61542253 0.25860949 0.97612402 0.95689776 0.27122381 0.24733825]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Precision: ', precision_score(y_test, y_pred, average = None))\n",
    "print('\\nRecall: ', recall_score(y_test, y_pred, average = None))\n",
    "print('\\nF1: ',f1_score(y_test, y_pred, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7356b-1ab1-4e5a-8d4f-7cb263d35352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7409f852-ad3f-4e55-9d1d-3f95750a2abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m recall_scores \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m auc_scores \u001b[38;5;241m=\u001b[39m [\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m)]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate overall accuracy\u001b[39;00m\n\u001b[1;32m     12\u001b[0m overall_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/miniconda3/envs/envmod/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/envmod/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:640\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    650\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    654\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/envmod/lib/python3.12/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/envmod/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n\u001b[1;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate precision, recall, F1 scores, and AUC for each class\n",
    "precision_scores = precision_score(y_test, y_pred, average=None)\n",
    "recall_scores = recall_score(y_test, y_pred, average=None)\n",
    "f1_scores = f1_score(y_test, y_pred, average=None)\n",
    "auc_scores = [roc_auc_score((y_test == i).astype(int), (y_pred == i).astype(int)) for i in range(1, 9)]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "overall_accuracy = round(overall_accuracy, 4)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Peatland', 'Mineral Wetland', 'Open Water', 'Forest', 'Vegetated Land', 'Barren Land']\n",
    "\n",
    "# Create bar plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(np.arange(len(class_names)) - 0.22, precision_scores, width=0.15, label=\"Precision (Producer's Accuracy)\", color='skyblue', edgecolor='black')\n",
    "plt.bar(np.arange(len(class_names)) - 0.07, recall_scores, width=0.15, label=\"Recall (User's Accuracy)\", color='lightgreen', edgecolor='black')\n",
    "plt.bar(np.arange(len(class_names)) + 0.08, f1_scores, width=0.15, label='F1 Score', color='orange', edgecolor='black')\n",
    "plt.bar(np.arange(len(class_names)) + 0.23, auc_scores, width=0.15, label='AUC', color='red', edgecolor='black')\n",
    "plt.axhline(overall_accuracy, color='black', linestyle='--', label=f'Overall Accuracy ({overall_accuracy})')\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "plt.xlabel('Class', fontsize=12, weight='bold')\n",
    "plt.ylabel('Score', fontsize=12, weight='bold')\n",
    "plt.title(f'Precision, Recall, F1 Score, AUC, and OA with {model_desc} ({trees} Trees)', fontsize=14, weight='bold')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), shadow=True, ncol=2)\n",
    "\n",
    "# Set y-axis grid every 0.1\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "# Add y-axis grid with subdivisions\n",
    "plt.grid(axis='y', which='major', color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'Figures/{model_desc}_Bargraph.png', bbox_inches='tight')  # Adjust the filename and path as needed\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890d37e-fa76-45e9-8679-02707b8a92ba",
   "metadata": {},
   "source": [
    "**Confusion Matrix Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c22060-63b4-4d47-bc3f-94420ba29021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Peatland', 'Mineral Wetland', 'Open Water', 'Forest', 'Vegetated Land', 'Barren Land']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "                 xticklabels=class_names, yticklabels=class_names, \n",
    "                 annot_kws={\"size\": 12, \"weight\": \"bold\"}, cbar=False)\n",
    "plt.xlabel('Predicted', fontsize=12, weight='bold')\n",
    "plt.ylabel('Actual', fontsize=12, weight='bold')\n",
    "plt.title(f'Confusion Matrix with {model_desc} ({trees} Trees)', fontsize=14, weight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Add color scale bar\n",
    "cbar = ax.figure.colorbar(ax.collections[0], ax=ax, location='right', pad=0.05)\n",
    "cbar.set_label('Number of Instances', fontsize=12, weight='bold')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'Figures/{model_desc}_Matrix.png', bbox_inches='tight')  # Adjust the filename and path as needed\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73398225-2035-4ef3-bc70-34a0b50196a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b7e6da-37ff-488a-9a77-34509cd67a1f",
   "metadata": {},
   "source": [
    "**The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1-specificity) for various classification thresholds. It illustrates how well the classifier can distinguish between positive instances and negative instances across different thresholds. Can be used to assess discriminative power and overall performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdab476-dabb-4a13-8cb7-293eb78e8ad9",
   "metadata": {},
   "source": [
    "**Display feature importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0caf83-a2ed-4639-9a49-f9eb283b4029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import rasterio\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the trained model\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Open the raster dataset to obtain band names\n",
    "with rasterio.open(image_ds_path) as dataset:\n",
    "    # Read the band names\n",
    "    band_names = dataset.descriptions\n",
    "\n",
    "# Get the number of bands\n",
    "num_bands = len(band_names)\n",
    "\n",
    "# Define the bar width to create some padding\n",
    "bar_width = 0.8\n",
    "\n",
    "# Plot feature importances with band names as labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(num_bands), importances, align='center', color='lightblue', edgecolor='black', width=bar_width)\n",
    "\n",
    "# Highlight the top 5 bar features in red and bold the label text\n",
    "top_indices = importances.argsort()[-5:][::-1]\n",
    "for i, bar in enumerate(bars):\n",
    "    if i in top_indices:\n",
    "        bar.set_color('red')\n",
    "        bar.set_edgecolor('black')\n",
    "        plt.xticks(range(num_bands), band_names, rotation=45, ha='right', fontsize=8)  # Resetting tick labels\n",
    "    \n",
    "# Bold the labels for the top 5 bands\n",
    "plt.xticks(range(num_bands), band_names, rotation=45, ha='right', fontsize=8)\n",
    "for i, tick in enumerate(plt.gca().get_xticklabels()):\n",
    "    if i in top_indices:\n",
    "        tick.set_weight('bold')  # Bold the label text for top 5 bands\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Set x-axis label, y-axis label, and title\n",
    "plt.xlabel('Band')\n",
    "plt.ylabel('Importance')\n",
    "plt.title(f'Feature Importances for {model_desc} (500 Trees)')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'Figures/{model_desc}_FeatureImportances.png', bbox_inches='tight')  # Adjust the filename and path as needed\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb4b8f-c66c-4537-af21-6f096ea8242c",
   "metadata": {},
   "source": [
    "**Create a classified .tif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bb495-b0b1-4f0b-a0a4-2f37aaecbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_image_file = image_ds_path\n",
    "with rasterio.open(covariate_image_file) as src:\n",
    "    output_meta = src.profile\n",
    "\n",
    "output_meta.update(count = 1, dtype = np.uint8, nodata = 255, compress = 'lzw')\n",
    "\n",
    "output_classified_file = f\"{model_desc}_Classified.tif\"\n",
    "\n",
    "def predict_row(row):\n",
    "    w = ((row,row+1), (None, None))\n",
    "    with rasterio.open(covariate_image_file) as src:\n",
    "        nodata = src.profile['nodata']\n",
    "        X = src.read(window = w)[:,0,:]\n",
    "    y_pred = rf.predict(X.T)\n",
    "    mask = np.where((X == nodata).any(axis = 0))\n",
    "    y_pred[mask] = 255\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "out_ds = rasterio.open(output_classified_file, \"w\", **output_meta)\n",
    "\n",
    "try:\n",
    "    print(f\"Predicting {output_meta['height']} rows:\", flush = True)\n",
    "    for row in range(output_meta['height']):\n",
    "        if row % 100 == 0:\n",
    "            print(row, \"...\", sep = '', end = '', flush = True)\n",
    "        y_pred = predict_row(row).reshape((1, output_meta['width']))\n",
    "        w = ((row, row+1), (None, None))\n",
    "        out_ds.write_band(1, y_pred, window = w)\n",
    "    print(\"done.\")\n",
    "finally:\n",
    "    out_ds.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f3732-239c-4cbb-bc1d-4afbce4820cd",
   "metadata": {},
   "source": [
    "**0 = NoData   \n",
    "1 = Peatlands   \n",
    "2 = Mineral Wetlands   \n",
    "3 = Open Water   \n",
    "4 = Forest   \n",
    "5 = Vegetated Land   \n",
    "6 = Barren Land**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704b3a5-1777-4c35-a348-89ba6bc33574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
